[["index.html", "Encyclopedia of Quantitative Methods in R, vol. 1: Data Wrangling Welcome Blocked Notes Code and Output The Authors", " Encyclopedia of Quantitative Methods in R, vol. 1: Data Wrangling Sarah Schwartz &amp; Tyson Barrett Last updated: 2021-08-31 Welcome Backgroup and links to other volumes of this encyclopedia may be found at the Encyclopedia’s Home Website. Blocked Notes Thoughout all the eBooks in this encyclopedia, several small secitons will be blocked out in the following ways: These blocks denote an area UNDER CONSTRUCTION, so check back often. This massive undertaking started during the summer of 2018 and is far from complete. The outline of seven volumes is given above despite any one being complete. Feedback is welcome via either author’s email. These blocks denote something EXTREMELY IMPORTANT. Do NOT skip these notes as they will be used very sparingly. These blocks denote something to DOWNLOAD. This may include software installations, example datasets, or notebook code files. These blocks denote something INTERESTING. These point out information we found of interest or added value. These blocks denote LINKS to other websites. This may include instructional video clips, articles, or blog posts. We are all about NOT re-creating the wheel. If somebody else has described or illustrated a topic well, we celebrate it! Code and Output This is how \\(R\\) code is shown: 1 + 1 This is what the output of the \\(R\\) code above will look: ## [1] 2 The Authors Dr. Sarah Schwartz Dr. Tyson Barrett www.SarahSchwartzStats.com www.TysonBarrett.com Sarah.Schwartz@usu.edu Tyson.Barrett@usu.edu Statistical Consulting Studio Data Science and Discover Unit Why choose R ? Check it out: an article from Fall 2016… No more excuses: R is better than SPSS for psychology undergrads, and students agree FYI This entire encyclopedia is written in \\(R Markdown\\), using \\(R Studio\\) as the text editor and the bookdown package to turn a collection of markdown documents into a coherent whole. The book’s source code is hosted on GitHub. If you notice typos or other issues, feel free to email either of the authors. This work is licensed under the Attribution-NonCommercial-NoDerivatives 4.0 International License. "],["data-in-and-out.html", "1 Data In and Out 1.1 Importing Data 1.2 Saving Data", " 1 Data In and Out 1.1 Importing Data R can import nearly any file type, but most importantly, it can work with CSV, SPSS, and Excel (since they are the most common forms for students in this course). 1.1.1 In a package First, some packages come with data. You can access these data by using: data(&quot;data_name&quot;) For example, dplyr comes with a star wars data set: library(dplyr) data(&quot;starwars&quot;) starwars ## # A tibble: 87 × 14 ## name height mass hair_color skin_color eye_color birth_year sex gender ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Luke S… 172 77 blond fair blue 19 male mascu… ## 2 C-3PO 167 75 &lt;NA&gt; gold yellow 112 none mascu… ## 3 R2-D2 96 32 &lt;NA&gt; white, bl… red 33 none mascu… ## 4 Darth … 202 136 none white yellow 41.9 male mascu… ## 5 Leia O… 150 49 brown light brown 19 fema… femin… ## 6 Owen L… 178 120 brown, grey light blue 52 male mascu… ## 7 Beru W… 165 75 brown light blue 47 fema… femin… ## 8 R5-D4 97 32 &lt;NA&gt; white, red red NA none mascu… ## 9 Biggs … 183 84 black light brown 24 male mascu… ## 10 Obi-Wa… 182 77 auburn, wh… fair blue-gray 57 male mascu… ## # … with 77 more rows, and 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, ## # films &lt;list&gt;, vehicles &lt;list&gt;, starships &lt;list&gt; 1.1.2 R (.RData) When data are saved from R, it can be saved as a .RData file. To import these, we can use: load(&quot;file.RData&quot;) where \"file.RData\" is the name of the file you are importing. 1.1.3 CSV, SPSS, Excel, Etc. The others can imported using the rio package’s import() function. data_csv &lt;- import(&quot;file.csv&quot;) data_excel &lt;- import(&quot;file.xlsx&quot;) data_spss &lt;- import(&quot;file.sav&quot;) 1.1.4 By hand tribble() You can also enter data by hand using the tribble() function from the tidyverse. tribble( ~var1, ~var2, 10, &quot;psychology&quot;, 12, &quot;biology&quot;, 7, &quot;psychology&quot; ) ## # A tibble: 3 × 2 ## var1 var2 ## &lt;dbl&gt; &lt;chr&gt; ## 1 10 psychology ## 2 12 biology ## 3 7 psychology 1.2 Saving Data You can always save data but often it isn’t necessary. Why is that? Because you will save your code that does all the stuff you want to do with the data anyway so no need to save it. However, sometimes other researchers want access to the cleaned data and they don’t use R so we’ll show a few examples. 1.2.1 R (.RData) save(data, &quot;file.RData&quot;) 1.2.2 CSV and Excel write_csv(data, &quot;file.csv&quot;) 1.2.3 SPSS (.sav) library(haven) write_sav(data, &quot;file.sav&quot;) "],["tidy-data.html", "2 Tidy Data 2.1 Define Tidy Data", " 2 Tidy Data Tidying up data is often where most of the data work happens. It is known by many names–cleaning, wrangling, tidying–but it all ultimately is to make the data in a format that we can analyze it. 2.1 Define Tidy Data Tidy data are discussed in many resources (e.g., R for Data Science). “Tidy datasets are all alike but every messy dataset is messy in its own way. Tidy datasets provide a standardized way to link the structure of a dataset (its physical layout) with its semantics (its meaning). In this section, I’ll provide some standard vocabulary for describing the structure and semantics of a dataset, and then use those definitions to define tidy data,” (https://vita.had.co.nz/papers/tidy-data.pdf). "],["cleaning-data.html", "3 Cleaning Data 3.1 Changing Variable Type 3.2 Changing a whole dataset to a certain class 3.3 Janitor Package 3.4 Washer function in the Furniture package 3.5 Forcats Package", " 3 Cleaning Data For examples, we are going to import some data from a .csv file. data &lt;- rio::import(&quot;data_csv.csv&quot;) 3.1 Changing Variable Type Importing data into R can cause your variables to change types. For example, lets see what the race variable class is now that the file has been imported into R. class(data$Race) ## [1] &quot;character&quot; As you see, its a character. We want it to be labeled as a factor. We can do this by using the as.factor() function in baseR. Make sure you save it as another variable in your dataset. If you don’t assign it to another variable, it will only temporarily show your variable as a factor but not actually change it to a factor for later analyses. data$RaceF &lt;- as.factor(data$Race) data$SmokingF &lt;- as.factor(data$smoking) Now lets see what the class of our RaceF variable is. class(data$RaceF) ## [1] &quot;factor&quot; Please note- when importing from a SAV file, some factors may be “haven-labelled.” Use this technique to change haven-labelled variables into factors as well. 3.2 Changing a whole dataset to a certain class If you want your whole dataset to be a certain class, you can easily do that in R using map_df(). Let’s say we want the whole dataset to be numeric. library(tidyverse) data_num &lt;- map_df(data, as.numeric) tibble::glimpse(data) ## Rows: 100 ## Columns: 16 ## $ V1 &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17… ## $ ID &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17… ## $ Educ &lt;int&gt; 14, 15, 23, 14, 22, 15, 23, 21, 21, 20, 13, 12, 22, 12, 2… ## $ Age &lt;int&gt; 58, 32, 47, 35, 51, 73, 46, 66, 38, 53, 19, 52, 24, 69, 5… ## $ Sex &lt;chr&gt; &quot;female&quot;, &quot;male&quot;, &quot;male&quot;, &quot;female&quot;, &quot;male&quot;, &quot;male&quot;, &quot;male… ## $ Race &lt;chr&gt; &quot;other&quot;, &quot;black&quot;, &quot;other&quot;, &quot;other&quot;, &quot;white&quot;, &quot;white&quot;, &quot;la… ## $ Married &lt;int&gt; 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, … ## $ Income_1 &lt;int&gt; 42504, 45341, 69261, 41654, 66149, 46009, 68791, 62362, 6… ## $ INCOME_2 &lt;int&gt; 56418, 59810, 92139, 56264, 88635, 59918, 91662, 83720, 8… ## $ Depression_1 &lt;int&gt; 23, 20, 16, 14, 10, 14, 13, 6, 20, 11, 24, 21, 12, 10, 10… ## $ Depression_2 &lt;int&gt; 26, 25, 20, 19, 13, 17, 17, 5, 26, 13, 28, 24, 14, 12, 12… ## $ Anx_1 &lt;int&gt; 21, 20, 15, 15, 8, 14, 16, 5, 17, 11, 26, 23, 12, 10, 12,… ## $ Anx_2 &lt;int&gt; 22, 23, 19, 10, 7, 16, 17, 4, 19, 10, 25, 22, 9, 12, 12, … ## $ smoking &lt;chr&gt; &quot;Non-smoker&quot;, &quot;Smoker&quot;, &quot;Smoker&quot;, &quot;99&quot;, &quot;Non-smoker&quot;, &quot;No… ## $ RaceF &lt;fct&gt; other, black, other, other, white, white, latinx, white, … ## $ SmokingF &lt;fct&gt; Non-smoker, Smoker, Smoker, 99, Non-smoker, Non-smoker, N… As you can see, the character and factor variables that do not contain numbers are unable to be numeric. We will go over how to change that later. You can also change the whole dataset to be factors using the same code, but changing as.numeric to as.factor. 3.3 Janitor Package The janitor package has useful functions that make it easy to clean your dataset. Use the clean_names() function to make variable names consistent. library(janitor) clean_df &lt;- clean_names(data) tibble::glimpse(clean_df) ## Rows: 100 ## Columns: 16 ## $ v1 &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17… ## $ id &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17… ## $ educ &lt;int&gt; 14, 15, 23, 14, 22, 15, 23, 21, 21, 20, 13, 12, 22, 12, 2… ## $ age &lt;int&gt; 58, 32, 47, 35, 51, 73, 46, 66, 38, 53, 19, 52, 24, 69, 5… ## $ sex &lt;chr&gt; &quot;female&quot;, &quot;male&quot;, &quot;male&quot;, &quot;female&quot;, &quot;male&quot;, &quot;male&quot;, &quot;male… ## $ race &lt;chr&gt; &quot;other&quot;, &quot;black&quot;, &quot;other&quot;, &quot;other&quot;, &quot;white&quot;, &quot;white&quot;, &quot;la… ## $ married &lt;int&gt; 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, … ## $ income_1 &lt;int&gt; 42504, 45341, 69261, 41654, 66149, 46009, 68791, 62362, 6… ## $ income_2 &lt;int&gt; 56418, 59810, 92139, 56264, 88635, 59918, 91662, 83720, 8… ## $ depression_1 &lt;int&gt; 23, 20, 16, 14, 10, 14, 13, 6, 20, 11, 24, 21, 12, 10, 10… ## $ depression_2 &lt;int&gt; 26, 25, 20, 19, 13, 17, 17, 5, 26, 13, 28, 24, 14, 12, 12… ## $ anx_1 &lt;int&gt; 21, 20, 15, 15, 8, 14, 16, 5, 17, 11, 26, 23, 12, 10, 12,… ## $ anx_2 &lt;int&gt; 22, 23, 19, 10, 7, 16, 17, 4, 19, 10, 25, 22, 9, 12, 12, … ## $ smoking &lt;chr&gt; &quot;Non-smoker&quot;, &quot;Smoker&quot;, &quot;Smoker&quot;, &quot;99&quot;, &quot;Non-smoker&quot;, &quot;No… ## $ race_f &lt;fct&gt; other, black, other, other, white, white, latinx, white, … ## $ smoking_f &lt;fct&gt; Non-smoker, Smoker, Smoker, 99, Non-smoker, Non-smoker, N… Now, all of our variables are lowercase and consistent. You can also remove columns and/or rows that are completely missing. We do not have any missing rows or columns in our real dataset, so we will make one up to show you how it works. df &lt;- data.frame(var1 = c(1, NA, 6, 8, 3), var2 = c(&quot;a&quot;, NA, &quot;c&quot;, &quot;s&quot;, &quot;y&quot;), var3 = c(NA, NA, NA, NA, NA)) df ## var1 var2 var3 ## 1 1 a NA ## 2 NA &lt;NA&gt; NA ## 3 6 c NA ## 4 8 s NA ## 5 3 y NA remove_empty(df, &quot;rows&quot;) ## var1 var2 var3 ## 1 1 a NA ## 3 6 c NA ## 4 8 s NA ## 5 3 y NA remove_empty(df, &quot;cols&quot;) ## var1 var2 ## 1 1 a ## 2 NA &lt;NA&gt; ## 3 6 c ## 4 8 s ## 5 3 y remove_empty(df, c(&quot;rows&quot;, &quot;cols&quot;)) ## var1 var2 ## 1 1 a ## 3 6 c ## 4 8 s ## 5 3 y 3.4 Washer function in the Furniture package library(furniture) washer(clean_df, 99, value = NA) ## v1 id educ age sex race married income_1 income_2 depression_1 ## 1 1 1 14 58 female other 0 42504 56418 23 ## 2 2 2 15 32 male black 0 45341 59810 20 ## 3 3 3 23 47 male other 0 69261 92139 16 ## 4 4 4 14 35 female other 1 41654 56264 14 ## 5 5 5 22 51 male white 0 66149 88635 10 ## 6 6 6 15 73 male white 1 46009 59918 14 ## 7 7 7 23 46 male latinx 1 68791 91662 13 ## 8 8 8 21 66 female white 1 62362 83720 6 ## 9 9 9 21 38 female other 0 62716 84363 20 ## 10 10 10 20 53 female white 1 60309 80255 11 ## 11 11 11 13 19 male latinx 0 38609 51231 24 ## 12 12 12 12 52 male latinx 0 35765 48350 21 ## 13 13 13 22 24 male latinx 0 65359 88375 12 ## 14 14 14 12 69 male latinx 1 35638 47970 10 ## 15 15 15 22 57 female latinx 1 66286 87292 10 ## 16 16 16 10 30 male black 1 29329 39557 4 ## 17 17 17 22 36 female latinx 1 65930 87958 16 ## 18 18 18 10 45 male black 0 30170 40493 17 ## 19 19 19 12 63 female latinx 1 36605 48624 17 ## 20 20 20 21 56 female black 0 62751 84363 5 ## 21 21 21 21 61 male black 0 63165 84272 16 ## 22 22 22 11 44 male other 0 33429 43882 4 ## 23 23 23 23 49 female latinx 0 68705 91403 13 ## 24 24 24 19 75 female other 1 57754 76665 17 ## 25 25 25 24 32 female white 0 71587 96584 5 ## 26 26 26 25 44 male white 0 75071 99362 10 ## 27 27 27 11 32 female latinx 1 31930 43994 25 ## 28 28 28 22 59 female white 1 65415 88285 10 ## 29 29 29 17 59 female latinx 1 51424 67933 9 ## 30 30 30 11 65 male latinx 1 33568 44797 14 ## 31 31 31 12 32 female black 0 35574 48605 20 ## 32 32 32 16 32 female other 1 48240 64209 20 ## 33 33 33 17 41 male white 0 51136 67940 10 ## 34 34 34 15 32 male latinx 1 45351 59612 10 ## 35 35 35 11 21 female latinx 1 33135 43671 7 ## 36 36 36 18 58 male black 1 53859 71889 17 ## 37 37 37 25 49 female white 0 74525 100518 5 ## 38 38 38 25 62 male white 0 75694 99834 18 ## 39 39 39 23 53 male white 0 69101 90538 24 ## 40 40 40 21 59 female latinx 0 63855 84479 18 ## 41 41 41 24 41 female white 0 71409 96501 25 ## 42 42 42 21 48 male white 0 63792 84229 22 ## 43 43 43 25 49 female black 0 74573 99489 16 ## 44 44 44 21 33 female black 0 63295 84883 8 ## 45 45 45 25 72 female white 1 75327 100158 9 ## 46 46 46 18 36 male white 1 53873 71979 13 ## 47 47 47 20 40 male black 1 59903 80448 21 ## 48 48 48 13 66 female white 0 38260 52552 17 ## 49 49 49 22 18 female latinx 1 66271 88650 4 ## 50 50 50 19 58 female white 1 58129 76397 8 ## 51 51 51 22 60 male other 0 66355 87677 7 ## 52 52 52 10 44 male latinx 1 29774 40207 12 ## 53 53 53 12 62 female other 0 35938 47879 22 ## 54 54 54 25 18 male black 0 75190 99326 12 ## 55 55 55 22 68 female latinx 1 66803 88144 9 ## 56 56 56 20 64 male other 0 59826 80546 22 ## 57 57 57 16 58 male latinx 0 49091 64723 11 ## 58 58 58 21 64 male white 1 63523 85150 22 ## 59 59 59 23 43 female white 1 68882 92108 13 ## 60 60 60 22 25 female black 0 65956 87883 18 ## 61 61 61 18 31 male white 1 53753 71406 17 ## 62 62 62 21 37 male latinx 0 62879 83837 16 ## 63 63 63 15 58 female white 0 45401 60718 17 ## 64 64 64 25 21 female black 0 75987 100466 4 ## 65 65 65 19 55 male black 0 56901 76335 11 ## 66 66 66 15 25 female black 0 44471 60007 6 ## 67 67 67 18 74 male white 1 54473 72169 21 ## 68 68 68 20 62 female white 0 59855 79460 11 ## 69 69 69 18 48 female black 0 53116 72916 6 ## 70 70 70 25 39 female white 0 75464 100441 7 ## 71 71 71 10 74 male white 0 30826 39582 15 ## 72 72 72 21 52 female black 1 62825 84191 25 ## 73 73 73 23 32 male latinx 0 69583 92592 10 ## 74 74 74 19 34 female latinx 1 57118 76277 18 ## 75 75 75 24 56 female other 1 72423 95471 16 ## 76 76 76 25 58 male white 0 75182 99402 18 ## 77 77 77 17 50 female white 0 51535 67826 23 ## 78 78 78 21 73 male latinx 0 62737 83835 11 ## 79 79 79 21 64 male latinx 1 63300 83430 13 ## 80 80 80 11 74 female black 0 33615 43182 5 ## 81 81 81 15 67 male other 1 44894 59759 11 ## 82 82 82 25 18 female latinx 1 75423 100193 5 ## 83 83 83 22 41 female other 0 65429 87471 16 ## 84 84 84 23 46 female white 0 69259 92073 10 ## 85 85 85 11 57 male latinx 0 32794 44572 19 ## 86 86 86 16 56 female black 0 49602 64341 21 ## 87 87 87 17 65 female other 0 51796 66755 7 ## 88 88 88 18 32 female white 0 54010 72606 8 ## 89 89 89 22 40 male latinx 1 64967 88133 15 ## 90 90 90 23 28 male white 1 69913 92558 18 ## 91 91 91 11 44 female white 0 33500 45197 5 ## 92 92 92 11 42 female latinx 0 33100 44187 4 ## 93 93 93 20 27 female latinx 1 59888 80343 13 ## 94 94 94 15 68 male latinx 0 44938 60644 23 ## 95 95 95 20 23 male latinx 1 59629 79479 25 ## 96 96 96 19 60 female white 1 56833 75545 20 ## 97 97 97 17 59 male black 1 50817 68483 6 ## 98 98 98 19 56 male latinx 0 57278 76339 8 ## 99 NA NA 21 53 male latinx 0 62614 84328 11 ## 100 100 100 22 49 female white 1 66983 87602 7 ## depression_2 anx_1 anx_2 smoking race_f smoking_f ## 1 26 21 22 Non-smoker other Non-smoker ## 2 25 20 23 Smoker black Smoker ## 3 20 15 19 Smoker other Smoker ## 4 19 15 10 &lt;NA&gt; other &lt;NA&gt; ## 5 13 8 7 Non-smoker white Non-smoker ## 6 17 14 16 Non-smoker white Non-smoker ## 7 17 16 17 Non-smoker latinx Non-smoker ## 8 5 5 4 Non-smoker white Non-smoker ## 9 26 17 19 Non-smoker other Non-smoker ## 10 13 11 10 Smoker white Smoker ## 11 28 26 25 &lt;NA&gt; latinx &lt;NA&gt; ## 12 24 23 22 Non-smoker latinx Non-smoker ## 13 14 12 9 Non-smoker latinx Non-smoker ## 14 12 10 12 Non-smoker latinx Non-smoker ## 15 12 12 12 Non-smoker latinx Non-smoker ## 16 7 5 7 Non-smoker black Non-smoker ## 17 19 17 18 Non-smoker latinx Non-smoker ## 18 22 18 16 Non-smoker black Non-smoker ## 19 21 16 17 Non-smoker latinx Non-smoker ## 20 7 3 3 Non-smoker black Non-smoker ## 21 17 16 16 Non-smoker black Non-smoker ## 22 5 3 7 Non-smoker other Non-smoker ## 23 17 10 10 &lt;NA&gt; latinx &lt;NA&gt; ## 24 19 20 20 Smoker other Smoker ## 25 6 4 2 &lt;NA&gt; white &lt;NA&gt; ## 26 13 9 10 &lt;NA&gt; white &lt;NA&gt; ## 27 31 25 27 &lt;NA&gt; latinx &lt;NA&gt; ## 28 12 8 10 Non-smoker white Non-smoker ## 29 12 9 10 Non-smoker latinx Non-smoker ## 30 17 13 12 &lt;NA&gt; latinx &lt;NA&gt; ## 31 24 21 23 Non-smoker black Non-smoker ## 32 24 25 25 Non-smoker other Non-smoker ## 33 13 13 11 Smoker white Smoker ## 34 11 8 6 Smoker latinx Smoker ## 35 8 4 7 Non-smoker latinx Non-smoker ## 36 19 17 17 Smoker black Smoker ## 37 5 3 7 Smoker white Smoker ## 38 23 20 22 Non-smoker white Non-smoker ## 39 29 25 24 Non-smoker white Non-smoker ## 40 23 14 17 Smoker latinx Smoker ## 41 31 26 21 Non-smoker white Non-smoker ## 42 25 22 25 Non-smoker white Non-smoker ## 43 18 15 16 Non-smoker black Non-smoker ## 44 10 7 7 Non-smoker black Non-smoker ## 45 11 9 8 &lt;NA&gt; white &lt;NA&gt; ## 46 16 14 13 Non-smoker white Non-smoker ## 47 26 19 15 Non-smoker black Non-smoker ## 48 21 18 19 Non-smoker white Non-smoker ## 49 6 5 2 Non-smoker latinx Non-smoker ## 50 8 3 1 &lt;NA&gt; white &lt;NA&gt; ## 51 8 -1 4 Non-smoker other Non-smoker ## 52 14 10 8 &lt;NA&gt; latinx &lt;NA&gt; ## 53 25 18 16 Non-smoker other Non-smoker ## 54 14 10 9 Non-smoker black Non-smoker ## 55 10 8 14 Non-smoker latinx Non-smoker ## 56 25 25 23 &lt;NA&gt; other &lt;NA&gt; ## 57 13 11 13 Non-smoker latinx Non-smoker ## 58 26 20 19 &lt;NA&gt; white &lt;NA&gt; ## 59 15 11 13 &lt;NA&gt; white &lt;NA&gt; ## 60 21 16 16 Non-smoker black Non-smoker ## 61 19 15 15 &lt;NA&gt; white &lt;NA&gt; ## 62 20 16 18 Non-smoker latinx Non-smoker ## 63 21 18 18 Non-smoker white Non-smoker ## 64 5 1 2 Non-smoker black Non-smoker ## 65 16 11 13 Non-smoker black Non-smoker ## 66 6 10 7 Non-smoker black Non-smoker ## 67 26 19 17 Non-smoker white Non-smoker ## 68 13 11 9 Non-smoker white Non-smoker ## 69 7 5 4 Non-smoker black Non-smoker ## 70 9 7 7 Non-smoker white Non-smoker ## 71 18 16 14 &lt;NA&gt; white &lt;NA&gt; ## 72 30 25 24 Non-smoker black Non-smoker ## 73 13 8 5 Non-smoker latinx Non-smoker ## 74 21 16 18 Non-smoker latinx Non-smoker ## 75 19 17 16 Non-smoker other Non-smoker ## 76 21 20 20 Non-smoker white Non-smoker ## 77 27 22 24 Non-smoker white Non-smoker ## 78 13 6 6 Non-smoker latinx Non-smoker ## 79 17 14 12 Non-smoker latinx Non-smoker ## 80 4 6 3 Non-smoker black Non-smoker ## 81 13 12 12 Non-smoker other Non-smoker ## 82 5 6 4 Non-smoker latinx Non-smoker ## 83 20 15 16 Smoker other Smoker ## 84 12 7 3 &lt;NA&gt; white &lt;NA&gt; ## 85 22 18 18 Non-smoker latinx Non-smoker ## 86 25 23 25 Non-smoker black Non-smoker ## 87 8 8 9 Non-smoker other Non-smoker ## 88 9 7 3 Non-smoker white Non-smoker ## 89 20 15 14 Non-smoker latinx Non-smoker ## 90 21 14 12 Smoker white Smoker ## 91 8 7 10 Smoker white Smoker ## 92 5 3 1 Non-smoker latinx Non-smoker ## 93 15 11 10 Non-smoker latinx Non-smoker ## 94 26 24 27 Non-smoker latinx Non-smoker ## 95 29 23 23 Smoker latinx Smoker ## 96 25 21 20 Non-smoker white Non-smoker ## 97 8 7 8 Non-smoker black Non-smoker ## 98 12 7 8 Non-smoker latinx Non-smoker ## 99 11 11 13 Smoker latinx Smoker ## 100 10 7 9 Non-smoker white Non-smoker 3.5 Forcats Package library(forcats) # forcats is also in tidyverse so if you downloaded tidyverse you don&#39;t need to download this as well 3.5.1 Relevel You can manually reorder factor levels fct_relevel(clean_df$race_f, &quot;white&quot;, &quot;black&quot;, &quot;latinx&quot;, &quot;other&quot;) ## [1] other black other other white white latinx white other white ## [11] latinx latinx latinx latinx latinx black latinx black latinx black ## [21] black other latinx other white white latinx white latinx latinx ## [31] black other white latinx latinx black white white white latinx ## [41] white white black black white white black white latinx white ## [51] other latinx other black latinx other latinx white white black ## [61] white latinx white black black black white white black white ## [71] white black latinx latinx other white white latinx latinx black ## [81] other latinx other white latinx black other white latinx white ## [91] white latinx latinx latinx latinx white black latinx latinx white ## Levels: white black latinx other 3.5.2 Reorder Reoder a factor by its levels’ frequency fct_infreq(clean_df$race_f) ## [1] other black other other white white latinx white other white ## [11] latinx latinx latinx latinx latinx black latinx black latinx black ## [21] black other latinx other white white latinx white latinx latinx ## [31] black other white latinx latinx black white white white latinx ## [41] white white black black white white black white latinx white ## [51] other latinx other black latinx other latinx white white black ## [61] white latinx white black black black white white black white ## [71] white black latinx latinx other white white latinx latinx black ## [81] other latinx other white latinx black other white latinx white ## [91] white latinx latinx latinx latinx white black latinx latinx white ## Levels: latinx white black other Reorder a factor by a numeric variable fct_reorder(clean_df$race_f, clean_df$income_1) ## [1] other black other other white white latinx white other white ## [11] latinx latinx latinx latinx latinx black latinx black latinx black ## [21] black other latinx other white white latinx white latinx latinx ## [31] black other white latinx latinx black white white white latinx ## [41] white white black black white white black white latinx white ## [51] other latinx other black latinx other latinx white white black ## [61] white latinx white black black black white white black white ## [71] white black latinx latinx other white white latinx latinx black ## [81] other latinx other white latinx black other white latinx white ## [91] white latinx latinx latinx latinx white black latinx latinx white ## Levels: other black latinx white 3.5.3 Lump When you have a factor with too many levels, you can lump all of the infrequent ones into one factor, “other.” You can specify how many levels you want to include. the argument “n” is the number of levels you want to keep, besides the “other” category that will be made from the lump function. You can also include the argument other_level = \"\" if you would like to change the name from other to something more specific. fct_lump(clean_df$race_f, n = 2) ## [1] Other Other Other Other white white latinx white Other white ## [11] latinx latinx latinx latinx latinx Other latinx Other latinx Other ## [21] Other Other latinx Other white white latinx white latinx latinx ## [31] Other Other white latinx latinx Other white white white latinx ## [41] white white Other Other white white Other white latinx white ## [51] Other latinx Other Other latinx Other latinx white white Other ## [61] white latinx white Other Other Other white white Other white ## [71] white Other latinx latinx Other white white latinx latinx Other ## [81] Other latinx Other white latinx Other Other white latinx white ## [91] white latinx latinx latinx latinx white Other latinx latinx white ## Levels: latinx white Other In this example, we previously had four levels of the race variable: white, black, latinx, and other. When we specified n = 2, we lumped the other and black categories (the most infrequent two) into one “Other” category. It kept our two most frequent categories: white and latinx. 3.5.4 Other Useful Functions for Factors Forcats cheat sheet "],["tidyverse.html", "4 Tidyverse 4.1 Pipes 4.2 Subset Data 4.3 Group_by 4.4 Mutate 4.5 Case_when 4.6 Cut Intervals", " 4 Tidyverse 4.1 Pipes me %&gt;% wake_up(“8:00am”) %&gt;% exercise(30, units = “minutes”) %&gt;% shower(15, units = “minutes”) %&gt;% eat_breakfast(“toast”) %&gt;% go_to_work(“basement”) Piping takes what is on the left-hand side and puts it in the right hand side’s function. If you look at the code below, you’ll see how code looks without a pipe. summary(clean_df) ## v1 id educ age ## Min. : 1.00 Min. : 1.00 Min. :10.00 Min. :18.00 ## 1st Qu.: 25.75 1st Qu.: 25.75 1st Qu.:15.00 1st Qu.:35.75 ## Median : 50.50 Median : 50.50 Median :20.00 Median :49.00 ## Mean : 50.50 Mean : 50.50 Mean :18.65 Mean :48.24 ## 3rd Qu.: 75.25 3rd Qu.: 75.25 3rd Qu.:22.00 3rd Qu.:59.25 ## Max. :100.00 Max. :100.00 Max. :25.00 Max. :75.00 ## sex race married income_1 ## Length:100 Length:100 Min. :0.00 Min. :29329 ## Class :character Class :character 1st Qu.:0.00 1st Qu.:45348 ## Mode :character Mode :character Median :0.00 Median :59840 ## Mean :0.43 Mean :56053 ## 3rd Qu.:1.00 3rd Qu.:66275 ## Max. :1.00 Max. :75987 ## income_2 depression_1 depression_2 anx_1 ## Min. : 39557 Min. : 4.00 Min. : 4.00 Min. :-1.00 ## 1st Qu.: 59985 1st Qu.: 9.00 1st Qu.:11.00 1st Qu.: 8.00 ## Median : 79867 Median :13.00 Median :17.00 Median :13.50 ## Mean : 74689 Mean :13.68 Mean :16.47 Mean :13.26 ## 3rd Qu.: 88179 3rd Qu.:18.00 3rd Qu.:22.00 3rd Qu.:18.00 ## Max. :100518 Max. :25.00 Max. :31.00 Max. :26.00 ## anx_2 smoking race_f smoking_f ## Min. : 1.0 Length:100 black :20 99 : 8 ## 1st Qu.: 8.0 Class :character latinx:33 Non-smoker:70 ## Median :13.0 Mode :character other :14 Smoker :14 ## Mean :13.3 white :33 NA&#39;s : 8 ## 3rd Qu.:18.0 ## Max. :27.0 Now, here is what the code looks like using a pipe. clean_df %&gt;% summary() ## v1 id educ age ## Min. : 1.00 Min. : 1.00 Min. :10.00 Min. :18.00 ## 1st Qu.: 25.75 1st Qu.: 25.75 1st Qu.:15.00 1st Qu.:35.75 ## Median : 50.50 Median : 50.50 Median :20.00 Median :49.00 ## Mean : 50.50 Mean : 50.50 Mean :18.65 Mean :48.24 ## 3rd Qu.: 75.25 3rd Qu.: 75.25 3rd Qu.:22.00 3rd Qu.:59.25 ## Max. :100.00 Max. :100.00 Max. :25.00 Max. :75.00 ## sex race married income_1 ## Length:100 Length:100 Min. :0.00 Min. :29329 ## Class :character Class :character 1st Qu.:0.00 1st Qu.:45348 ## Mode :character Mode :character Median :0.00 Median :59840 ## Mean :0.43 Mean :56053 ## 3rd Qu.:1.00 3rd Qu.:66275 ## Max. :1.00 Max. :75987 ## income_2 depression_1 depression_2 anx_1 ## Min. : 39557 Min. : 4.00 Min. : 4.00 Min. :-1.00 ## 1st Qu.: 59985 1st Qu.: 9.00 1st Qu.:11.00 1st Qu.: 8.00 ## Median : 79867 Median :13.00 Median :17.00 Median :13.50 ## Mean : 74689 Mean :13.68 Mean :16.47 Mean :13.26 ## 3rd Qu.: 88179 3rd Qu.:18.00 3rd Qu.:22.00 3rd Qu.:18.00 ## Max. :100518 Max. :25.00 Max. :31.00 Max. :26.00 ## anx_2 smoking race_f smoking_f ## Min. : 1.0 Length:100 black :20 99 : 8 ## 1st Qu.: 8.0 Class :character latinx:33 Non-smoker:70 ## Median :13.0 Mode :character other :14 Smoker :14 ## Mean :13.3 white :33 NA&#39;s : 8 ## 3rd Qu.:18.0 ## Max. :27.0 It may not seem to make the code more readable, but the more complex your code is the easier it will be to read it using pipes. It also allows you to connect multiple lines of code without having to overwrite your dataset multiple times. As we go through more data cleaning and wrangling, you’ll begin to see how piping makes a difference when coding. 4.2 Subset Data 4.2.1 Select function The select function allows you to pull specific information out of our dataset. You can do this using baseR commands, or with the select function from tidyverse. clean_df[, c(&quot;id&quot;, &quot;educ&quot;, &quot;age&quot;)] ## id educ age ## 1 1 14 58 ## 2 2 15 32 ## 3 3 23 47 ## 4 4 14 35 ## 5 5 22 51 ## 6 6 15 73 ## 7 7 23 46 ## 8 8 21 66 ## 9 9 21 38 ## 10 10 20 53 ## 11 11 13 19 ## 12 12 12 52 ## 13 13 22 24 ## 14 14 12 69 ## 15 15 22 57 ## 16 16 10 30 ## 17 17 22 36 ## 18 18 10 45 ## 19 19 12 63 ## 20 20 21 56 ## 21 21 21 61 ## 22 22 11 44 ## 23 23 23 49 ## 24 24 19 75 ## 25 25 24 32 ## 26 26 25 44 ## 27 27 11 32 ## 28 28 22 59 ## 29 29 17 59 ## 30 30 11 65 ## 31 31 12 32 ## 32 32 16 32 ## 33 33 17 41 ## 34 34 15 32 ## 35 35 11 21 ## 36 36 18 58 ## 37 37 25 49 ## 38 38 25 62 ## 39 39 23 53 ## 40 40 21 59 ## 41 41 24 41 ## 42 42 21 48 ## 43 43 25 49 ## 44 44 21 33 ## 45 45 25 72 ## 46 46 18 36 ## 47 47 20 40 ## 48 48 13 66 ## 49 49 22 18 ## 50 50 19 58 ## 51 51 22 60 ## 52 52 10 44 ## 53 53 12 62 ## 54 54 25 18 ## 55 55 22 68 ## 56 56 20 64 ## 57 57 16 58 ## 58 58 21 64 ## 59 59 23 43 ## 60 60 22 25 ## 61 61 18 31 ## 62 62 21 37 ## 63 63 15 58 ## 64 64 25 21 ## 65 65 19 55 ## 66 66 15 25 ## 67 67 18 74 ## 68 68 20 62 ## 69 69 18 48 ## 70 70 25 39 ## 71 71 10 74 ## 72 72 21 52 ## 73 73 23 32 ## 74 74 19 34 ## 75 75 24 56 ## 76 76 25 58 ## 77 77 17 50 ## 78 78 21 73 ## 79 79 21 64 ## 80 80 11 74 ## 81 81 15 67 ## 82 82 25 18 ## 83 83 22 41 ## 84 84 23 46 ## 85 85 11 57 ## 86 86 16 56 ## 87 87 17 65 ## 88 88 18 32 ## 89 89 22 40 ## 90 90 23 28 ## 91 91 11 44 ## 92 92 11 42 ## 93 93 20 27 ## 94 94 15 68 ## 95 95 20 23 ## 96 96 19 60 ## 97 97 17 59 ## 98 98 19 56 ## 99 99 21 53 ## 100 100 22 49 clean_df[, c(1:3)] ## v1 id educ ## 1 1 1 14 ## 2 2 2 15 ## 3 3 3 23 ## 4 4 4 14 ## 5 5 5 22 ## 6 6 6 15 ## 7 7 7 23 ## 8 8 8 21 ## 9 9 9 21 ## 10 10 10 20 ## 11 11 11 13 ## 12 12 12 12 ## 13 13 13 22 ## 14 14 14 12 ## 15 15 15 22 ## 16 16 16 10 ## 17 17 17 22 ## 18 18 18 10 ## 19 19 19 12 ## 20 20 20 21 ## 21 21 21 21 ## 22 22 22 11 ## 23 23 23 23 ## 24 24 24 19 ## 25 25 25 24 ## 26 26 26 25 ## 27 27 27 11 ## 28 28 28 22 ## 29 29 29 17 ## 30 30 30 11 ## 31 31 31 12 ## 32 32 32 16 ## 33 33 33 17 ## 34 34 34 15 ## 35 35 35 11 ## 36 36 36 18 ## 37 37 37 25 ## 38 38 38 25 ## 39 39 39 23 ## 40 40 40 21 ## 41 41 41 24 ## 42 42 42 21 ## 43 43 43 25 ## 44 44 44 21 ## 45 45 45 25 ## 46 46 46 18 ## 47 47 47 20 ## 48 48 48 13 ## 49 49 49 22 ## 50 50 50 19 ## 51 51 51 22 ## 52 52 52 10 ## 53 53 53 12 ## 54 54 54 25 ## 55 55 55 22 ## 56 56 56 20 ## 57 57 57 16 ## 58 58 58 21 ## 59 59 59 23 ## 60 60 60 22 ## 61 61 61 18 ## 62 62 62 21 ## 63 63 63 15 ## 64 64 64 25 ## 65 65 65 19 ## 66 66 66 15 ## 67 67 67 18 ## 68 68 68 20 ## 69 69 69 18 ## 70 70 70 25 ## 71 71 71 10 ## 72 72 72 21 ## 73 73 73 23 ## 74 74 74 19 ## 75 75 75 24 ## 76 76 76 25 ## 77 77 77 17 ## 78 78 78 21 ## 79 79 79 21 ## 80 80 80 11 ## 81 81 81 15 ## 82 82 82 25 ## 83 83 83 22 ## 84 84 84 23 ## 85 85 85 11 ## 86 86 86 16 ## 87 87 87 17 ## 88 88 88 18 ## 89 89 89 22 ## 90 90 90 23 ## 91 91 91 11 ## 92 92 92 11 ## 93 93 93 20 ## 94 94 94 15 ## 95 95 95 20 ## 96 96 96 19 ## 97 97 97 17 ## 98 98 98 19 ## 99 99 99 21 ## 100 100 100 22 clean_df %&gt;% select(id, educ, age) ## id educ age ## 1 1 14 58 ## 2 2 15 32 ## 3 3 23 47 ## 4 4 14 35 ## 5 5 22 51 ## 6 6 15 73 ## 7 7 23 46 ## 8 8 21 66 ## 9 9 21 38 ## 10 10 20 53 ## 11 11 13 19 ## 12 12 12 52 ## 13 13 22 24 ## 14 14 12 69 ## 15 15 22 57 ## 16 16 10 30 ## 17 17 22 36 ## 18 18 10 45 ## 19 19 12 63 ## 20 20 21 56 ## 21 21 21 61 ## 22 22 11 44 ## 23 23 23 49 ## 24 24 19 75 ## 25 25 24 32 ## 26 26 25 44 ## 27 27 11 32 ## 28 28 22 59 ## 29 29 17 59 ## 30 30 11 65 ## 31 31 12 32 ## 32 32 16 32 ## 33 33 17 41 ## 34 34 15 32 ## 35 35 11 21 ## 36 36 18 58 ## 37 37 25 49 ## 38 38 25 62 ## 39 39 23 53 ## 40 40 21 59 ## 41 41 24 41 ## 42 42 21 48 ## 43 43 25 49 ## 44 44 21 33 ## 45 45 25 72 ## 46 46 18 36 ## 47 47 20 40 ## 48 48 13 66 ## 49 49 22 18 ## 50 50 19 58 ## 51 51 22 60 ## 52 52 10 44 ## 53 53 12 62 ## 54 54 25 18 ## 55 55 22 68 ## 56 56 20 64 ## 57 57 16 58 ## 58 58 21 64 ## 59 59 23 43 ## 60 60 22 25 ## 61 61 18 31 ## 62 62 21 37 ## 63 63 15 58 ## 64 64 25 21 ## 65 65 19 55 ## 66 66 15 25 ## 67 67 18 74 ## 68 68 20 62 ## 69 69 18 48 ## 70 70 25 39 ## 71 71 10 74 ## 72 72 21 52 ## 73 73 23 32 ## 74 74 19 34 ## 75 75 24 56 ## 76 76 25 58 ## 77 77 17 50 ## 78 78 21 73 ## 79 79 21 64 ## 80 80 11 74 ## 81 81 15 67 ## 82 82 25 18 ## 83 83 22 41 ## 84 84 23 46 ## 85 85 11 57 ## 86 86 16 56 ## 87 87 17 65 ## 88 88 18 32 ## 89 89 22 40 ## 90 90 23 28 ## 91 91 11 44 ## 92 92 11 42 ## 93 93 20 27 ## 94 94 15 68 ## 95 95 20 23 ## 96 96 19 60 ## 97 97 17 59 ## 98 98 19 56 ## 99 99 21 53 ## 100 100 22 49 clean_df %&gt;% select(1:3) ## v1 id educ ## 1 1 1 14 ## 2 2 2 15 ## 3 3 3 23 ## 4 4 4 14 ## 5 5 5 22 ## 6 6 6 15 ## 7 7 7 23 ## 8 8 8 21 ## 9 9 9 21 ## 10 10 10 20 ## 11 11 11 13 ## 12 12 12 12 ## 13 13 13 22 ## 14 14 14 12 ## 15 15 15 22 ## 16 16 16 10 ## 17 17 17 22 ## 18 18 18 10 ## 19 19 19 12 ## 20 20 20 21 ## 21 21 21 21 ## 22 22 22 11 ## 23 23 23 23 ## 24 24 24 19 ## 25 25 25 24 ## 26 26 26 25 ## 27 27 27 11 ## 28 28 28 22 ## 29 29 29 17 ## 30 30 30 11 ## 31 31 31 12 ## 32 32 32 16 ## 33 33 33 17 ## 34 34 34 15 ## 35 35 35 11 ## 36 36 36 18 ## 37 37 37 25 ## 38 38 38 25 ## 39 39 39 23 ## 40 40 40 21 ## 41 41 41 24 ## 42 42 42 21 ## 43 43 43 25 ## 44 44 44 21 ## 45 45 45 25 ## 46 46 46 18 ## 47 47 47 20 ## 48 48 48 13 ## 49 49 49 22 ## 50 50 50 19 ## 51 51 51 22 ## 52 52 52 10 ## 53 53 53 12 ## 54 54 54 25 ## 55 55 55 22 ## 56 56 56 20 ## 57 57 57 16 ## 58 58 58 21 ## 59 59 59 23 ## 60 60 60 22 ## 61 61 61 18 ## 62 62 62 21 ## 63 63 63 15 ## 64 64 64 25 ## 65 65 65 19 ## 66 66 66 15 ## 67 67 67 18 ## 68 68 68 20 ## 69 69 69 18 ## 70 70 70 25 ## 71 71 71 10 ## 72 72 72 21 ## 73 73 73 23 ## 74 74 74 19 ## 75 75 75 24 ## 76 76 76 25 ## 77 77 77 17 ## 78 78 78 21 ## 79 79 79 21 ## 80 80 80 11 ## 81 81 81 15 ## 82 82 82 25 ## 83 83 83 22 ## 84 84 84 23 ## 85 85 85 11 ## 86 86 86 16 ## 87 87 87 17 ## 88 88 88 18 ## 89 89 89 22 ## 90 90 90 23 ## 91 91 91 11 ## 92 92 92 11 ## 93 93 93 20 ## 94 94 94 15 ## 95 95 95 20 ## 96 96 96 19 ## 97 97 97 17 ## 98 98 98 19 ## 99 99 99 21 ## 100 100 100 22 Each code chunk does the same thing. The first two, using [, is the “base R” way of selecting variables. The last two, using the pipe, is the tidyverse way. Both work great so the choice is yours. 4.2.2 starts_with(), ends_with(), contains() When you use tidyverse, you can pull variables out that have common features. Here are a few examples. Note that we use the select function as well as another function to pull out information. This line of code pulls out the variables that start with the word “income.” clean_df %&gt;% select(starts_with(&quot;income&quot;)) ## income_1 income_2 ## 1 42504 56418 ## 2 45341 59810 ## 3 69261 92139 ## 4 41654 56264 ## 5 66149 88635 ## 6 46009 59918 ## 7 68791 91662 ## 8 62362 83720 ## 9 62716 84363 ## 10 60309 80255 ## 11 38609 51231 ## 12 35765 48350 ## 13 65359 88375 ## 14 35638 47970 ## 15 66286 87292 ## 16 29329 39557 ## 17 65930 87958 ## 18 30170 40493 ## 19 36605 48624 ## 20 62751 84363 ## 21 63165 84272 ## 22 33429 43882 ## 23 68705 91403 ## 24 57754 76665 ## 25 71587 96584 ## 26 75071 99362 ## 27 31930 43994 ## 28 65415 88285 ## 29 51424 67933 ## 30 33568 44797 ## 31 35574 48605 ## 32 48240 64209 ## 33 51136 67940 ## 34 45351 59612 ## 35 33135 43671 ## 36 53859 71889 ## 37 74525 100518 ## 38 75694 99834 ## 39 69101 90538 ## 40 63855 84479 ## 41 71409 96501 ## 42 63792 84229 ## 43 74573 99489 ## 44 63295 84883 ## 45 75327 100158 ## 46 53873 71979 ## 47 59903 80448 ## 48 38260 52552 ## 49 66271 88650 ## 50 58129 76397 ## 51 66355 87677 ## 52 29774 40207 ## 53 35938 47879 ## 54 75190 99326 ## 55 66803 88144 ## 56 59826 80546 ## 57 49091 64723 ## 58 63523 85150 ## 59 68882 92108 ## 60 65956 87883 ## 61 53753 71406 ## 62 62879 83837 ## 63 45401 60718 ## 64 75987 100466 ## 65 56901 76335 ## 66 44471 60007 ## 67 54473 72169 ## 68 59855 79460 ## 69 53116 72916 ## 70 75464 100441 ## 71 30826 39582 ## 72 62825 84191 ## 73 69583 92592 ## 74 57118 76277 ## 75 72423 95471 ## 76 75182 99402 ## 77 51535 67826 ## 78 62737 83835 ## 79 63300 83430 ## 80 33615 43182 ## 81 44894 59759 ## 82 75423 100193 ## 83 65429 87471 ## 84 69259 92073 ## 85 32794 44572 ## 86 49602 64341 ## 87 51796 66755 ## 88 54010 72606 ## 89 64967 88133 ## 90 69913 92558 ## 91 33500 45197 ## 92 33100 44187 ## 93 59888 80343 ## 94 44938 60644 ## 95 59629 79479 ## 96 56833 75545 ## 97 50817 68483 ## 98 57278 76339 ## 99 62614 84328 ## 100 66983 87602 This code allows you to select all of the variables in your dataset that end with _1 and _2. clean_df %&gt;% select(ends_with(c(&quot;_1&quot;, &quot;_2&quot;))) ## income_1 depression_1 anx_1 income_2 depression_2 anx_2 ## 1 42504 23 21 56418 26 22 ## 2 45341 20 20 59810 25 23 ## 3 69261 16 15 92139 20 19 ## 4 41654 14 15 56264 19 10 ## 5 66149 10 8 88635 13 7 ## 6 46009 14 14 59918 17 16 ## 7 68791 13 16 91662 17 17 ## 8 62362 6 5 83720 5 4 ## 9 62716 20 17 84363 26 19 ## 10 60309 11 11 80255 13 10 ## 11 38609 24 26 51231 28 25 ## 12 35765 21 23 48350 24 22 ## 13 65359 12 12 88375 14 9 ## 14 35638 10 10 47970 12 12 ## 15 66286 10 12 87292 12 12 ## 16 29329 4 5 39557 7 7 ## 17 65930 16 17 87958 19 18 ## 18 30170 17 18 40493 22 16 ## 19 36605 17 16 48624 21 17 ## 20 62751 5 3 84363 7 3 ## 21 63165 16 16 84272 17 16 ## 22 33429 4 3 43882 5 7 ## 23 68705 13 10 91403 17 10 ## 24 57754 17 20 76665 19 20 ## 25 71587 5 4 96584 6 2 ## 26 75071 10 9 99362 13 10 ## 27 31930 25 25 43994 31 27 ## 28 65415 10 8 88285 12 10 ## 29 51424 9 9 67933 12 10 ## 30 33568 14 13 44797 17 12 ## 31 35574 20 21 48605 24 23 ## 32 48240 20 25 64209 24 25 ## 33 51136 10 13 67940 13 11 ## 34 45351 10 8 59612 11 6 ## 35 33135 7 4 43671 8 7 ## 36 53859 17 17 71889 19 17 ## 37 74525 5 3 100518 5 7 ## 38 75694 18 20 99834 23 22 ## 39 69101 24 25 90538 29 24 ## 40 63855 18 14 84479 23 17 ## 41 71409 25 26 96501 31 21 ## 42 63792 22 22 84229 25 25 ## 43 74573 16 15 99489 18 16 ## 44 63295 8 7 84883 10 7 ## 45 75327 9 9 100158 11 8 ## 46 53873 13 14 71979 16 13 ## 47 59903 21 19 80448 26 15 ## 48 38260 17 18 52552 21 19 ## 49 66271 4 5 88650 6 2 ## 50 58129 8 3 76397 8 1 ## 51 66355 7 -1 87677 8 4 ## 52 29774 12 10 40207 14 8 ## 53 35938 22 18 47879 25 16 ## 54 75190 12 10 99326 14 9 ## 55 66803 9 8 88144 10 14 ## 56 59826 22 25 80546 25 23 ## 57 49091 11 11 64723 13 13 ## 58 63523 22 20 85150 26 19 ## 59 68882 13 11 92108 15 13 ## 60 65956 18 16 87883 21 16 ## 61 53753 17 15 71406 19 15 ## 62 62879 16 16 83837 20 18 ## 63 45401 17 18 60718 21 18 ## 64 75987 4 1 100466 5 2 ## 65 56901 11 11 76335 16 13 ## 66 44471 6 10 60007 6 7 ## 67 54473 21 19 72169 26 17 ## 68 59855 11 11 79460 13 9 ## 69 53116 6 5 72916 7 4 ## 70 75464 7 7 100441 9 7 ## 71 30826 15 16 39582 18 14 ## 72 62825 25 25 84191 30 24 ## 73 69583 10 8 92592 13 5 ## 74 57118 18 16 76277 21 18 ## 75 72423 16 17 95471 19 16 ## 76 75182 18 20 99402 21 20 ## 77 51535 23 22 67826 27 24 ## 78 62737 11 6 83835 13 6 ## 79 63300 13 14 83430 17 12 ## 80 33615 5 6 43182 4 3 ## 81 44894 11 12 59759 13 12 ## 82 75423 5 6 100193 5 4 ## 83 65429 16 15 87471 20 16 ## 84 69259 10 7 92073 12 3 ## 85 32794 19 18 44572 22 18 ## 86 49602 21 23 64341 25 25 ## 87 51796 7 8 66755 8 9 ## 88 54010 8 7 72606 9 3 ## 89 64967 15 15 88133 20 14 ## 90 69913 18 14 92558 21 12 ## 91 33500 5 7 45197 8 10 ## 92 33100 4 3 44187 5 1 ## 93 59888 13 11 80343 15 10 ## 94 44938 23 24 60644 26 27 ## 95 59629 25 23 79479 29 23 ## 96 56833 20 21 75545 25 20 ## 97 50817 6 7 68483 8 8 ## 98 57278 8 7 76339 12 8 ## 99 62614 11 11 84328 11 13 ## 100 66983 7 7 87602 10 9 With this code you can pull out any variables that contain “anx” anywhere in the variable name. clean_df %&gt;% select(contains(&quot;anx&quot;)) ## anx_1 anx_2 ## 1 21 22 ## 2 20 23 ## 3 15 19 ## 4 15 10 ## 5 8 7 ## 6 14 16 ## 7 16 17 ## 8 5 4 ## 9 17 19 ## 10 11 10 ## 11 26 25 ## 12 23 22 ## 13 12 9 ## 14 10 12 ## 15 12 12 ## 16 5 7 ## 17 17 18 ## 18 18 16 ## 19 16 17 ## 20 3 3 ## 21 16 16 ## 22 3 7 ## 23 10 10 ## 24 20 20 ## 25 4 2 ## 26 9 10 ## 27 25 27 ## 28 8 10 ## 29 9 10 ## 30 13 12 ## 31 21 23 ## 32 25 25 ## 33 13 11 ## 34 8 6 ## 35 4 7 ## 36 17 17 ## 37 3 7 ## 38 20 22 ## 39 25 24 ## 40 14 17 ## 41 26 21 ## 42 22 25 ## 43 15 16 ## 44 7 7 ## 45 9 8 ## 46 14 13 ## 47 19 15 ## 48 18 19 ## 49 5 2 ## 50 3 1 ## 51 -1 4 ## 52 10 8 ## 53 18 16 ## 54 10 9 ## 55 8 14 ## 56 25 23 ## 57 11 13 ## 58 20 19 ## 59 11 13 ## 60 16 16 ## 61 15 15 ## 62 16 18 ## 63 18 18 ## 64 1 2 ## 65 11 13 ## 66 10 7 ## 67 19 17 ## 68 11 9 ## 69 5 4 ## 70 7 7 ## 71 16 14 ## 72 25 24 ## 73 8 5 ## 74 16 18 ## 75 17 16 ## 76 20 20 ## 77 22 24 ## 78 6 6 ## 79 14 12 ## 80 6 3 ## 81 12 12 ## 82 6 4 ## 83 15 16 ## 84 7 3 ## 85 18 18 ## 86 23 25 ## 87 8 9 ## 88 7 3 ## 89 15 14 ## 90 14 12 ## 91 7 10 ## 92 3 1 ## 93 11 10 ## 94 24 27 ## 95 23 23 ## 96 21 20 ## 97 7 8 ## 98 7 8 ## 99 11 13 ## 100 7 9 4.2.3 Filter, equality/inequality, and/or, within clean_df[clean_df$anx_1 &gt; 20,] ## v1 id educ age sex race married income_1 income_2 depression_1 ## 1 1 1 14 58 female other 0 42504 56418 23 ## 11 11 11 13 19 male latinx 0 38609 51231 24 ## 12 12 12 12 52 male latinx 0 35765 48350 21 ## 27 27 27 11 32 female latinx 1 31930 43994 25 ## 31 31 31 12 32 female black 0 35574 48605 20 ## 32 32 32 16 32 female other 1 48240 64209 20 ## 39 39 39 23 53 male white 0 69101 90538 24 ## 41 41 41 24 41 female white 0 71409 96501 25 ## 42 42 42 21 48 male white 0 63792 84229 22 ## 56 56 56 20 64 male other 0 59826 80546 22 ## 72 72 72 21 52 female black 1 62825 84191 25 ## 77 77 77 17 50 female white 0 51535 67826 23 ## 86 86 86 16 56 female black 0 49602 64341 21 ## 94 94 94 15 68 male latinx 0 44938 60644 23 ## 95 95 95 20 23 male latinx 1 59629 79479 25 ## 96 96 96 19 60 female white 1 56833 75545 20 ## depression_2 anx_1 anx_2 smoking race_f smoking_f ## 1 26 21 22 Non-smoker other Non-smoker ## 11 28 26 25 &lt;NA&gt; latinx &lt;NA&gt; ## 12 24 23 22 Non-smoker latinx Non-smoker ## 27 31 25 27 &lt;NA&gt; latinx &lt;NA&gt; ## 31 24 21 23 Non-smoker black Non-smoker ## 32 24 25 25 Non-smoker other Non-smoker ## 39 29 25 24 Non-smoker white Non-smoker ## 41 31 26 21 Non-smoker white Non-smoker ## 42 25 22 25 Non-smoker white Non-smoker ## 56 25 25 23 99 other 99 ## 72 30 25 24 Non-smoker black Non-smoker ## 77 27 22 24 Non-smoker white Non-smoker ## 86 25 23 25 Non-smoker black Non-smoker ## 94 26 24 27 Non-smoker latinx Non-smoker ## 95 29 23 23 Smoker latinx Smoker ## 96 25 21 20 Non-smoker white Non-smoker clean_df %&gt;% filter(anx_1 &gt; 20) ## v1 id educ age sex race married income_1 income_2 depression_1 ## 1 1 1 14 58 female other 0 42504 56418 23 ## 2 11 11 13 19 male latinx 0 38609 51231 24 ## 3 12 12 12 52 male latinx 0 35765 48350 21 ## 4 27 27 11 32 female latinx 1 31930 43994 25 ## 5 31 31 12 32 female black 0 35574 48605 20 ## 6 32 32 16 32 female other 1 48240 64209 20 ## 7 39 39 23 53 male white 0 69101 90538 24 ## 8 41 41 24 41 female white 0 71409 96501 25 ## 9 42 42 21 48 male white 0 63792 84229 22 ## 10 56 56 20 64 male other 0 59826 80546 22 ## 11 72 72 21 52 female black 1 62825 84191 25 ## 12 77 77 17 50 female white 0 51535 67826 23 ## 13 86 86 16 56 female black 0 49602 64341 21 ## 14 94 94 15 68 male latinx 0 44938 60644 23 ## 15 95 95 20 23 male latinx 1 59629 79479 25 ## 16 96 96 19 60 female white 1 56833 75545 20 ## depression_2 anx_1 anx_2 smoking race_f smoking_f ## 1 26 21 22 Non-smoker other Non-smoker ## 2 28 26 25 &lt;NA&gt; latinx &lt;NA&gt; ## 3 24 23 22 Non-smoker latinx Non-smoker ## 4 31 25 27 &lt;NA&gt; latinx &lt;NA&gt; ## 5 24 21 23 Non-smoker black Non-smoker ## 6 24 25 25 Non-smoker other Non-smoker ## 7 29 25 24 Non-smoker white Non-smoker ## 8 31 26 21 Non-smoker white Non-smoker ## 9 25 22 25 Non-smoker white Non-smoker ## 10 25 25 23 99 other 99 ## 11 30 25 24 Non-smoker black Non-smoker ## 12 27 22 24 Non-smoker white Non-smoker ## 13 25 23 25 Non-smoker black Non-smoker ## 14 26 24 27 Non-smoker latinx Non-smoker ## 15 29 23 23 Smoker latinx Smoker ## 16 25 21 20 Non-smoker white Non-smoker clean_df %&gt;% filter(sex == &quot;female&quot;) ## v1 id educ age sex race married income_1 income_2 depression_1 ## 1 1 1 14 58 female other 0 42504 56418 23 ## 2 4 4 14 35 female other 1 41654 56264 14 ## 3 8 8 21 66 female white 1 62362 83720 6 ## 4 9 9 21 38 female other 0 62716 84363 20 ## 5 10 10 20 53 female white 1 60309 80255 11 ## 6 15 15 22 57 female latinx 1 66286 87292 10 ## 7 17 17 22 36 female latinx 1 65930 87958 16 ## 8 19 19 12 63 female latinx 1 36605 48624 17 ## 9 20 20 21 56 female black 0 62751 84363 5 ## 10 23 23 23 49 female latinx 0 68705 91403 13 ## 11 24 24 19 75 female other 1 57754 76665 17 ## 12 25 25 24 32 female white 0 71587 96584 5 ## 13 27 27 11 32 female latinx 1 31930 43994 25 ## 14 28 28 22 59 female white 1 65415 88285 10 ## 15 29 29 17 59 female latinx 1 51424 67933 9 ## 16 31 31 12 32 female black 0 35574 48605 20 ## 17 32 32 16 32 female other 1 48240 64209 20 ## 18 35 35 11 21 female latinx 1 33135 43671 7 ## 19 37 37 25 49 female white 0 74525 100518 5 ## 20 40 40 21 59 female latinx 0 63855 84479 18 ## 21 41 41 24 41 female white 0 71409 96501 25 ## 22 43 43 25 49 female black 0 74573 99489 16 ## 23 44 44 21 33 female black 0 63295 84883 8 ## 24 45 45 25 72 female white 1 75327 100158 9 ## 25 48 48 13 66 female white 0 38260 52552 17 ## 26 49 49 22 18 female latinx 1 66271 88650 4 ## 27 50 50 19 58 female white 1 58129 76397 8 ## 28 53 53 12 62 female other 0 35938 47879 22 ## 29 55 55 22 68 female latinx 1 66803 88144 9 ## 30 59 59 23 43 female white 1 68882 92108 13 ## 31 60 60 22 25 female black 0 65956 87883 18 ## 32 63 63 15 58 female white 0 45401 60718 17 ## 33 64 64 25 21 female black 0 75987 100466 4 ## 34 66 66 15 25 female black 0 44471 60007 6 ## 35 68 68 20 62 female white 0 59855 79460 11 ## 36 69 69 18 48 female black 0 53116 72916 6 ## 37 70 70 25 39 female white 0 75464 100441 7 ## 38 72 72 21 52 female black 1 62825 84191 25 ## 39 74 74 19 34 female latinx 1 57118 76277 18 ## 40 75 75 24 56 female other 1 72423 95471 16 ## 41 77 77 17 50 female white 0 51535 67826 23 ## 42 80 80 11 74 female black 0 33615 43182 5 ## 43 82 82 25 18 female latinx 1 75423 100193 5 ## 44 83 83 22 41 female other 0 65429 87471 16 ## 45 84 84 23 46 female white 0 69259 92073 10 ## 46 86 86 16 56 female black 0 49602 64341 21 ## 47 87 87 17 65 female other 0 51796 66755 7 ## 48 88 88 18 32 female white 0 54010 72606 8 ## 49 91 91 11 44 female white 0 33500 45197 5 ## 50 92 92 11 42 female latinx 0 33100 44187 4 ## 51 93 93 20 27 female latinx 1 59888 80343 13 ## 52 96 96 19 60 female white 1 56833 75545 20 ## 53 100 100 22 49 female white 1 66983 87602 7 ## depression_2 anx_1 anx_2 smoking race_f smoking_f ## 1 26 21 22 Non-smoker other Non-smoker ## 2 19 15 10 99 other 99 ## 3 5 5 4 Non-smoker white Non-smoker ## 4 26 17 19 Non-smoker other Non-smoker ## 5 13 11 10 Smoker white Smoker ## 6 12 12 12 Non-smoker latinx Non-smoker ## 7 19 17 18 Non-smoker latinx Non-smoker ## 8 21 16 17 Non-smoker latinx Non-smoker ## 9 7 3 3 Non-smoker black Non-smoker ## 10 17 10 10 &lt;NA&gt; latinx &lt;NA&gt; ## 11 19 20 20 Smoker other Smoker ## 12 6 4 2 99 white 99 ## 13 31 25 27 &lt;NA&gt; latinx &lt;NA&gt; ## 14 12 8 10 Non-smoker white Non-smoker ## 15 12 9 10 Non-smoker latinx Non-smoker ## 16 24 21 23 Non-smoker black Non-smoker ## 17 24 25 25 Non-smoker other Non-smoker ## 18 8 4 7 Non-smoker latinx Non-smoker ## 19 5 3 7 Smoker white Smoker ## 20 23 14 17 Smoker latinx Smoker ## 21 31 26 21 Non-smoker white Non-smoker ## 22 18 15 16 Non-smoker black Non-smoker ## 23 10 7 7 Non-smoker black Non-smoker ## 24 11 9 8 &lt;NA&gt; white &lt;NA&gt; ## 25 21 18 19 Non-smoker white Non-smoker ## 26 6 5 2 Non-smoker latinx Non-smoker ## 27 8 3 1 &lt;NA&gt; white &lt;NA&gt; ## 28 25 18 16 Non-smoker other Non-smoker ## 29 10 8 14 Non-smoker latinx Non-smoker ## 30 15 11 13 99 white 99 ## 31 21 16 16 Non-smoker black Non-smoker ## 32 21 18 18 Non-smoker white Non-smoker ## 33 5 1 2 Non-smoker black Non-smoker ## 34 6 10 7 Non-smoker black Non-smoker ## 35 13 11 9 Non-smoker white Non-smoker ## 36 7 5 4 Non-smoker black Non-smoker ## 37 9 7 7 Non-smoker white Non-smoker ## 38 30 25 24 Non-smoker black Non-smoker ## 39 21 16 18 Non-smoker latinx Non-smoker ## 40 19 17 16 Non-smoker other Non-smoker ## 41 27 22 24 Non-smoker white Non-smoker ## 42 4 6 3 Non-smoker black Non-smoker ## 43 5 6 4 Non-smoker latinx Non-smoker ## 44 20 15 16 Smoker other Smoker ## 45 12 7 3 99 white 99 ## 46 25 23 25 Non-smoker black Non-smoker ## 47 8 8 9 Non-smoker other Non-smoker ## 48 9 7 3 Non-smoker white Non-smoker ## 49 8 7 10 Smoker white Smoker ## 50 5 3 1 Non-smoker latinx Non-smoker ## 51 15 11 10 Non-smoker latinx Non-smoker ## 52 25 21 20 Non-smoker white Non-smoker ## 53 10 7 9 Non-smoker white Non-smoker clean_df %&gt;% filter(sex == &quot;female&quot; &amp; race == &quot;black&quot;) ## v1 id educ age sex race married income_1 income_2 depression_1 ## 1 20 20 21 56 female black 0 62751 84363 5 ## 2 31 31 12 32 female black 0 35574 48605 20 ## 3 43 43 25 49 female black 0 74573 99489 16 ## 4 44 44 21 33 female black 0 63295 84883 8 ## 5 60 60 22 25 female black 0 65956 87883 18 ## 6 64 64 25 21 female black 0 75987 100466 4 ## 7 66 66 15 25 female black 0 44471 60007 6 ## 8 69 69 18 48 female black 0 53116 72916 6 ## 9 72 72 21 52 female black 1 62825 84191 25 ## 10 80 80 11 74 female black 0 33615 43182 5 ## 11 86 86 16 56 female black 0 49602 64341 21 ## depression_2 anx_1 anx_2 smoking race_f smoking_f ## 1 7 3 3 Non-smoker black Non-smoker ## 2 24 21 23 Non-smoker black Non-smoker ## 3 18 15 16 Non-smoker black Non-smoker ## 4 10 7 7 Non-smoker black Non-smoker ## 5 21 16 16 Non-smoker black Non-smoker ## 6 5 1 2 Non-smoker black Non-smoker ## 7 6 10 7 Non-smoker black Non-smoker ## 8 7 5 4 Non-smoker black Non-smoker ## 9 30 25 24 Non-smoker black Non-smoker ## 10 4 6 3 Non-smoker black Non-smoker ## 11 25 23 25 Non-smoker black Non-smoker clean_df %&gt;% filter(sex == &quot;female&quot; | educ == 20) ## v1 id educ age sex race married income_1 income_2 depression_1 ## 1 1 1 14 58 female other 0 42504 56418 23 ## 2 4 4 14 35 female other 1 41654 56264 14 ## 3 8 8 21 66 female white 1 62362 83720 6 ## 4 9 9 21 38 female other 0 62716 84363 20 ## 5 10 10 20 53 female white 1 60309 80255 11 ## 6 15 15 22 57 female latinx 1 66286 87292 10 ## 7 17 17 22 36 female latinx 1 65930 87958 16 ## 8 19 19 12 63 female latinx 1 36605 48624 17 ## 9 20 20 21 56 female black 0 62751 84363 5 ## 10 23 23 23 49 female latinx 0 68705 91403 13 ## 11 24 24 19 75 female other 1 57754 76665 17 ## 12 25 25 24 32 female white 0 71587 96584 5 ## 13 27 27 11 32 female latinx 1 31930 43994 25 ## 14 28 28 22 59 female white 1 65415 88285 10 ## 15 29 29 17 59 female latinx 1 51424 67933 9 ## 16 31 31 12 32 female black 0 35574 48605 20 ## 17 32 32 16 32 female other 1 48240 64209 20 ## 18 35 35 11 21 female latinx 1 33135 43671 7 ## 19 37 37 25 49 female white 0 74525 100518 5 ## 20 40 40 21 59 female latinx 0 63855 84479 18 ## 21 41 41 24 41 female white 0 71409 96501 25 ## 22 43 43 25 49 female black 0 74573 99489 16 ## 23 44 44 21 33 female black 0 63295 84883 8 ## 24 45 45 25 72 female white 1 75327 100158 9 ## 25 47 47 20 40 male black 1 59903 80448 21 ## 26 48 48 13 66 female white 0 38260 52552 17 ## 27 49 49 22 18 female latinx 1 66271 88650 4 ## 28 50 50 19 58 female white 1 58129 76397 8 ## 29 53 53 12 62 female other 0 35938 47879 22 ## 30 55 55 22 68 female latinx 1 66803 88144 9 ## 31 56 56 20 64 male other 0 59826 80546 22 ## 32 59 59 23 43 female white 1 68882 92108 13 ## 33 60 60 22 25 female black 0 65956 87883 18 ## 34 63 63 15 58 female white 0 45401 60718 17 ## 35 64 64 25 21 female black 0 75987 100466 4 ## 36 66 66 15 25 female black 0 44471 60007 6 ## 37 68 68 20 62 female white 0 59855 79460 11 ## 38 69 69 18 48 female black 0 53116 72916 6 ## 39 70 70 25 39 female white 0 75464 100441 7 ## 40 72 72 21 52 female black 1 62825 84191 25 ## 41 74 74 19 34 female latinx 1 57118 76277 18 ## 42 75 75 24 56 female other 1 72423 95471 16 ## 43 77 77 17 50 female white 0 51535 67826 23 ## 44 80 80 11 74 female black 0 33615 43182 5 ## 45 82 82 25 18 female latinx 1 75423 100193 5 ## 46 83 83 22 41 female other 0 65429 87471 16 ## 47 84 84 23 46 female white 0 69259 92073 10 ## 48 86 86 16 56 female black 0 49602 64341 21 ## 49 87 87 17 65 female other 0 51796 66755 7 ## 50 88 88 18 32 female white 0 54010 72606 8 ## 51 91 91 11 44 female white 0 33500 45197 5 ## 52 92 92 11 42 female latinx 0 33100 44187 4 ## 53 93 93 20 27 female latinx 1 59888 80343 13 ## 54 95 95 20 23 male latinx 1 59629 79479 25 ## 55 96 96 19 60 female white 1 56833 75545 20 ## 56 100 100 22 49 female white 1 66983 87602 7 ## depression_2 anx_1 anx_2 smoking race_f smoking_f ## 1 26 21 22 Non-smoker other Non-smoker ## 2 19 15 10 99 other 99 ## 3 5 5 4 Non-smoker white Non-smoker ## 4 26 17 19 Non-smoker other Non-smoker ## 5 13 11 10 Smoker white Smoker ## 6 12 12 12 Non-smoker latinx Non-smoker ## 7 19 17 18 Non-smoker latinx Non-smoker ## 8 21 16 17 Non-smoker latinx Non-smoker ## 9 7 3 3 Non-smoker black Non-smoker ## 10 17 10 10 &lt;NA&gt; latinx &lt;NA&gt; ## 11 19 20 20 Smoker other Smoker ## 12 6 4 2 99 white 99 ## 13 31 25 27 &lt;NA&gt; latinx &lt;NA&gt; ## 14 12 8 10 Non-smoker white Non-smoker ## 15 12 9 10 Non-smoker latinx Non-smoker ## 16 24 21 23 Non-smoker black Non-smoker ## 17 24 25 25 Non-smoker other Non-smoker ## 18 8 4 7 Non-smoker latinx Non-smoker ## 19 5 3 7 Smoker white Smoker ## 20 23 14 17 Smoker latinx Smoker ## 21 31 26 21 Non-smoker white Non-smoker ## 22 18 15 16 Non-smoker black Non-smoker ## 23 10 7 7 Non-smoker black Non-smoker ## 24 11 9 8 &lt;NA&gt; white &lt;NA&gt; ## 25 26 19 15 Non-smoker black Non-smoker ## 26 21 18 19 Non-smoker white Non-smoker ## 27 6 5 2 Non-smoker latinx Non-smoker ## 28 8 3 1 &lt;NA&gt; white &lt;NA&gt; ## 29 25 18 16 Non-smoker other Non-smoker ## 30 10 8 14 Non-smoker latinx Non-smoker ## 31 25 25 23 99 other 99 ## 32 15 11 13 99 white 99 ## 33 21 16 16 Non-smoker black Non-smoker ## 34 21 18 18 Non-smoker white Non-smoker ## 35 5 1 2 Non-smoker black Non-smoker ## 36 6 10 7 Non-smoker black Non-smoker ## 37 13 11 9 Non-smoker white Non-smoker ## 38 7 5 4 Non-smoker black Non-smoker ## 39 9 7 7 Non-smoker white Non-smoker ## 40 30 25 24 Non-smoker black Non-smoker ## 41 21 16 18 Non-smoker latinx Non-smoker ## 42 19 17 16 Non-smoker other Non-smoker ## 43 27 22 24 Non-smoker white Non-smoker ## 44 4 6 3 Non-smoker black Non-smoker ## 45 5 6 4 Non-smoker latinx Non-smoker ## 46 20 15 16 Smoker other Smoker ## 47 12 7 3 99 white 99 ## 48 25 23 25 Non-smoker black Non-smoker ## 49 8 8 9 Non-smoker other Non-smoker ## 50 9 7 3 Non-smoker white Non-smoker ## 51 8 7 10 Smoker white Smoker ## 52 5 3 1 Non-smoker latinx Non-smoker ## 53 15 11 10 Non-smoker latinx Non-smoker ## 54 29 23 23 Smoker latinx Smoker ## 55 25 21 20 Non-smoker white Non-smoker ## 56 10 7 9 Non-smoker white Non-smoker 4.3 Group_by The group_by() function allows for us to group our data by a specific variable and compare groups with descriptive statistics. clean_df %&gt;% group_by(race_f) %&gt;% summarize(N = n(), mean = mean(depression_1), sd = sd(depression_1)) ## # A tibble: 4 × 4 ## race_f N mean sd ## &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 black 20 12.9 6.93 ## 2 latinx 33 13.5 5.75 ## 3 other 14 15.4 6.10 ## 4 white 33 13.6 6.09 This example groups the dataset by race_f and summarizes it by the number per race (the n() argument), and provides the mean (mean()) and standard deviation (sd()) for depression scores by race. 4.4 Mutate Anytime you see mutate() it means you are adding a new variable or modifying an existing one. For example, lets take a look at what class our sex variable is. class(clean_df$sex) ## [1] &quot;character&quot; When we imported the data, R did not know sex was a factor. So, we need to change it to be factor. Using the mutate function allows us to modify existing variables, or create new variables. In this case, I make a new variable called “sex_f” and change sex to be a factor. clean_df &lt;- clean_df %&gt;% mutate(sex_f = factor(sex)) class(clean_df$sex_f) ## [1] &quot;factor&quot; 4.5 Case_when When you want to modify variables based on various possible conditions, you can use the case_when() function. For example, when a categorical variable is dummy-coded to be 0,1,2.. you can change it to have actual name labels. In this example, our married variable i supposed to be factor of 0 = not married and 1 = married. Lets look at our married variable before we use mutate and case_when. summary(clean_df$married) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.00 0.00 0.00 0.43 1.00 1.00 The next code chunk will show a new variable, called “married_f” that has levels “married” and “not married” and is a factor. To do this, we need to use mutate to create the new married_f variable, and then tell r that when the married variable = 1, then label married, and if married = 0, label it not married. Note that we need to use == to specify that it is equal to something. We also need to put our labels in \"\" when they are words. The last line of code turns married_f into a factor, rather than a character variable. clean_df &lt;- clean_df %&gt;% mutate(married_f = case_when( married == 1 ~ &quot;married&quot;, married == 0 ~ &quot;not married&quot; ) %&gt;% as.factor()) clean_df$married_f %&gt;% summary() ## married not married ## 43 57 4.6 Cut Intervals To be added "],["joining-datasets.html", "5 Joining Datasets 5.1 types of joining", " 5 Joining Datasets 5.1 types of joining "],["changing-structure.html", "6 Changing Structure 6.1 Wide vs. Long", " 6 Changing Structure 6.1 Wide vs. Long 6.1.1 tidyr::gather() 6.1.2 tidyr::spread() "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
